{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marceloBilbyIA/transferLearningCatsAndDogs/blob/main/Transfer_Learning_Cats_and_Dogs_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izQ8TCWf2_rT"
      },
      "source": [
        "IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xBSbsyIi1szh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.io import read_file\n",
        "import tensorflow as tf\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De9ElEG53usj"
      },
      "source": [
        "DOWNLOAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGC7FF4K3zj8",
        "outputId": "f8680f2c-cc44-46b5-c81a-e99833e86b0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Cat and Dogs for image notebooks\n",
            "############################################################################################# 100.0%\n",
            "renamed 'PetImages/Cat' -> 'PetImages/train/Cat'\n",
            "renamed 'PetImages/Dog' -> 'PetImages/train/Dog'\n"
          ]
        }
      ],
      "source": [
        "!echo \"Downloading Cat and Dogs for image notebooks\"\n",
        "!curl -L -o kagglecatsanddogs_5340.zip --progress-bar https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
        "!rm -rf PetImages\n",
        "!unzip -q kagglecatsanddogs_5340.zip\n",
        "!rm -rf kagglecatsanddogs_5340.zip\n",
        "!mkdir -p PetImages/train\n",
        "!mkdir -p PetImages/validation\n",
        "!mkdir -p PetImages/validation/Cat\n",
        "!mkdir -p PetImages/validation/Dog\n",
        "!mv -v -f -t PetImages/train PetImages/Cat\n",
        "!mv -v -f -t PetImages/train PetImages/Dog\n",
        "!rm -rf CDLA-Permissive-2.0.pdf\n",
        "!rm -rf readme\\[1\\].txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8bw9H-9SHNj"
      },
      "source": [
        "REMOVING CORRUPT IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqElh1mHSXl5",
        "outputId": "296114e0-5d17-4afb-e57e-23377cf284d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Erro ao processar PetImages/train/Cat/10404.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "PetImages/train/Cat/10501.jpg\n",
            "PetImages/train/Cat/10820.jpg\n",
            "PetImages/train/Cat/11210.jpg\n",
            "PetImages/train/Cat/11565.jpg\n",
            "PetImages/train/Cat/11874.jpg\n",
            "PetImages/train/Cat/11935.jpg\n",
            "PetImages/train/Cat/140.jpg\n",
            "PetImages/train/Cat/2663.jpg\n",
            "PetImages/train/Cat/3300.jpg\n",
            "PetImages/train/Cat/3491.jpg\n",
            "Erro ao processar PetImages/train/Cat/4351.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input size should match (header_size + row_size * abs_height) but they differ by 2 [Op:DecodeImage] name: \n",
            "PetImages/train/Cat/4833.jpg\n",
            "PetImages/train/Cat/5553.jpg\n",
            "PetImages/train/Cat/660.jpg\n",
            "Erro ao processar PetImages/train/Cat/666.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input is empty. [Op:DecodeImage] name: \n",
            "PetImages/train/Cat/7968.jpg\n",
            "PetImages/train/Cat/7978.jpg\n",
            "PetImages/train/Cat/8470.jpg\n",
            "PetImages/train/Cat/850.jpg\n",
            "PetImages/train/Cat/9171.jpg\n",
            "PetImages/train/Cat/936.jpg\n",
            "PetImages/train/Cat/9565.jpg\n",
            "PetImages/train/Cat/9778.jpg\n",
            "PetImages/train/Dog/10158.jpg\n",
            "PetImages/train/Dog/10401.jpg\n",
            "PetImages/train/Dog/10747.jpg\n",
            "PetImages/train/Dog/10797.jpg\n",
            "Erro ao processar PetImages/train/Dog/11233.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Number of channels inherent in the image must be 1, 3 or 4, was 2 [Op:DecodeImage] name: \n",
            "PetImages/train/Dog/11410.jpg\n",
            "PetImages/train/Dog/11675.jpg\n",
            "Erro ao processar PetImages/train/Dog/11702.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input is empty. [Op:DecodeImage] name: \n",
            "PetImages/train/Dog/11849.jpg\n",
            "PetImages/train/Dog/11853.jpg\n",
            "Erro ao processar PetImages/train/Dog/11912.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Number of channels inherent in the image must be 1, 3 or 4, was 2 [Op:DecodeImage] name: \n",
            "PetImages/train/Dog/1308.jpg\n",
            "PetImages/train/Dog/1866.jpg\n",
            "Erro ao processar PetImages/train/Dog/2317.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Number of channels inherent in the image must be 1, 3 or 4, was 2 [Op:DecodeImage] name: \n",
            "PetImages/train/Dog/2384.jpg\n",
            "Erro ao processar PetImages/train/Dog/2494.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input size should match (header_size + row_size * abs_height) but they differ by 2 [Op:DecodeImage] name: \n",
            "PetImages/train/Dog/2688.jpg\n",
            "PetImages/train/Dog/2877.jpg\n",
            "PetImages/train/Dog/3136.jpg\n",
            "PetImages/train/Dog/3288.jpg\n",
            "PetImages/train/Dog/3588.jpg\n",
            "PetImages/train/Dog/4367.jpg\n",
            "PetImages/train/Dog/5604.jpg\n",
            "PetImages/train/Dog/5736.jpg\n",
            "PetImages/train/Dog/6059.jpg\n",
            "PetImages/train/Dog/6238.jpg\n",
            "PetImages/train/Dog/6718.jpg\n",
            "PetImages/train/Dog/7112.jpg\n",
            "PetImages/train/Dog/7133.jpg\n",
            "PetImages/train/Dog/7369.jpg\n",
            "PetImages/train/Dog/7459.jpg\n",
            "PetImages/train/Dog/7969.jpg\n",
            "PetImages/train/Dog/8730.jpg\n",
            "PetImages/train/Dog/9188.jpg\n",
            "Erro ao processar PetImages/train/Dog/9500.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Number of channels inherent in the image must be 1, 3 or 4, was 2 [Op:DecodeImage] name: \n"
          ]
        }
      ],
      "source": [
        "deleted = 0\n",
        "base_dir = \"PetImages\"\n",
        "folders = [\"train/Cat/*.jpg\", \"train/Dog/*.jpg\"]\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(base_dir, folder)\n",
        "    for image in sorted(glob.glob(folder_path)):\n",
        "      try:\n",
        "          img = read_file(str(image))\n",
        "          img = tf.io.decode_image(img, channels=3)\n",
        "          if img.shape[2] != 3:\n",
        "             print(image)\n",
        "             os.remove(image)\n",
        "      except Exception as e:\n",
        "            print(f\"Erro ao processar {image}: {e}\")\n",
        "            os.remove(image)  # Opcional: remova imagens corrompidas\n",
        "            deleted += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOUdg85XJDJx"
      },
      "source": [
        "DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5uAZZBzJJZN"
      },
      "outputs": [],
      "source": [
        "base = \"/content/PetImages\"\n",
        "train = os.path.join(base, \"train\")\n",
        "validation = os.path.join(base, \"validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKIwg2plMGg_"
      },
      "source": [
        "PRE PROCCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmwEil5mMKlK"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0M5WwLmMmIN",
        "outputId": "98f64d0b-2607-45bf-d3e2-c6fb4da841e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 24940 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0UMAmSyNrRM",
        "outputId": "dbc8bf87-c4d3-492f-8797-0b582f0938ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "val_generator = validation_datagen.flow_from_directory(\n",
        "    validation,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRj6gZ8KOwez"
      },
      "source": [
        "ARCHITECTURE VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUdxfQuFPCJu",
        "outputId": "d0682b76-c7cb-4dc0-b0b0-41a90ad61b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx--uHDYPI7y"
      },
      "source": [
        "MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWSP-SD0PKvC"
      },
      "outputs": [],
      "source": [
        "x = Flatten()(base_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NmndTRqPSqe"
      },
      "source": [
        "COMPILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9IcoXH8PYLy"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8KieCrUPeSR"
      },
      "source": [
        "TRAIN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZXmy2oQPgUG",
        "outputId": "4720c350-c614-42ac-ef21-b76853a25c9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m471/780\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:31:31\u001b[0m 18s/step - accuracy: 0.8542 - loss: 0.3278"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKL4fvflPnnm"
      },
      "source": [
        "ASSESSMENT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix4kJsN_Pqjb"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnyBDoDpJxXH"
      },
      "source": [
        "PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8y97IWzJ06U"
      },
      "outputs": [],
      "source": [
        "def predict_image(img_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Expande a dimensão para batch único\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    if prediction[0] < 0.5:\n",
        "        print(\"É um Gato!\")\n",
        "    else:\n",
        "        print(\"É um Cachorro!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXrHBR9E02hX"
      },
      "source": [
        "EXECUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2iA4FRi077b",
        "outputId": "33097dd3-450c-4b12-f4e3-a59d94285b0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841ms/step\n",
            "É um Gato!\n"
          ]
        }
      ],
      "source": [
        "predict_image(\"/content/ImagensParaTeste/gatos4.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWq9fRQNyra3",
        "outputId": "3b1ce8cb-69f0-49c3-d1ae-52bfdf101207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n"
          ]
        }
      ],
      "source": [
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmVSnDVwy2Fc",
        "outputId": "9cebce22-c316-4f2d-e973-24117a5877c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accuracy': [0.8288692831993103], 'loss': [0.3989183008670807], 'val_accuracy': [1.0], 'val_loss': [0.054208554327487946]}\n"
          ]
        }
      ],
      "source": [
        "print(history.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01AvETa31Dwo"
      },
      "source": [
        "VISUALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsW-p-JR1J5j"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEuWNfDgDj/RfBt+3Ea7jo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}